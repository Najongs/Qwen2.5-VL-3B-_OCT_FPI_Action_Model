{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af088b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RealTimeMultiviewDataset 생성 중...\n",
      "데이터셋 생성 완료.\n",
      "DataLoader 생성 중... (Batch Size = 4)\n",
      "DataLoader 생성 완료.\n",
      "\n",
      "첫 번째 배치 로딩 시도...\n",
      "2025-10-24 16:23:04,675 - INFO - Dataset iterator 시작. /home/najo/NAS/VLA/Qwen2.5-VL-3B-_OCT_FPI_Action_Model/Real_Env_Test 탐색...\n",
      "2025-10-24 16:23:04,676 - INFO - --- 세션 폴더 처리 시작: recv_all_20251022_044355 ---\n",
      "2025-10-24 16:23:04,678 - INFO - Loading sensor data from /home/najo/NAS/VLA/Qwen2.5-VL-3B-_OCT_FPI_Action_Model/Real_Env_Test/recv_all_20251022_044355/robot_state_20251022_044355.csv...\n",
      "2025-10-24 16:23:04,752 - INFO - ✅ CSV 로드 성공! 총 5130개 데이터 포인트.\n",
      "2025-10-24 16:23:04,754 - WARNING -   'View2_left' 폴더에 이미지가 없습니다.\n",
      "2025-10-24 16:23:04,755 - WARNING -   'View4_left' 폴더에 이미지가 없습니다.\n",
      "2025-10-24 16:23:04,757 - INFO -   이미지 인덱싱 완료. 5130개 센서 데이터와 매칭 시작...\n",
      "2025-10-24 16:23:04,784 - INFO - --- 세션 처리 완료: 0개 데이터 포인트 생성 ---\n",
      "2025-10-24 16:23:04,785 - INFO - --- 세션 폴더 처리 시작: recv_all_20251023_150612 ---\n",
      "2025-10-24 16:23:04,787 - INFO - Loading sensor data from /home/najo/NAS/VLA/Qwen2.5-VL-3B-_OCT_FPI_Action_Model/Real_Env_Test/recv_all_20251023_150612/robot_state_20251023_150612.csv...\n",
      "2025-10-24 16:23:04,848 - INFO - ✅ CSV 로드 성공! 총 5537개 데이터 포인트.\n",
      "2025-10-24 16:23:04,850 - INFO -   이미지 인덱싱 완료. 5537개 센서 데이터와 매칭 시작...\n",
      "✅ 첫 번째 배치 로드 성공! (소요 시간: 1.06초)\n",
      "\n",
      "==============================\n",
      " 첫 번째 배치 정보 (Batch 0)\n",
      "==============================\n",
      "  Key: 'pixel_values'\n",
      "    Shape: torch.Size([4, 9, 3, 224, 224])\n",
      "    Dtype: torch.float32\n",
      "  Key: 'joints'\n",
      "    Shape: torch.Size([4, 6])\n",
      "    Dtype: torch.float32\n",
      "  Key: 'pose'\n",
      "    Shape: torch.Size([4, 6])\n",
      "    Dtype: torch.float32\n",
      "  Key: 'timestamp'\n",
      "    Shape: torch.Size([4])\n",
      "    Dtype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import logging\n",
    "import sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import Optional, List, Tuple, Dict, Any\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# --- 설정 ---\n",
    "# 데이터가 저장된 기본 경로\n",
    "BASE_PATH = Path(\"/home/najo/NAS/VLA/Qwen2.5-VL-3B-_OCT_FPI_Action_Model/Real_Env_Test/\")\n",
    "\n",
    "# 뷰 이름과 해당 하위 폴더 경로 (View5는 하위 폴더 없음)\n",
    "# 이 키(key)들이 최종적으로 데이터에 포함될 뷰 이름이 됩니다.\n",
    "VIEW_CONFIG = {\n",
    "    \"View1_left\": \"View1/left\",\n",
    "    \"View1_right\": \"View1/right\",\n",
    "    \"View2_left\": \"View2/left\",\n",
    "    \"View2_right\": \"View2/right\",\n",
    "    \"View3_left\": \"View3/left\",\n",
    "    \"View3_right\": \"View3/right\",\n",
    "    \"View4_left\": \"View4/left\",\n",
    "    \"View4_right\": \"View4/right\",\n",
    "    \"View5\": \"View5\", # View5는 하위 폴더 없음\n",
    "}\n",
    "# 이미지 파일 확장자\n",
    "IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
    "# 센서-이미지 간 최대 허용 시간 차이 (초)\n",
    "MATCH_TOLERANCE_SEC = 0.1 \n",
    "\n",
    "# CSV 헤더에서 찾을 열 이름 및 인덱스\n",
    "CSV_TIMESTAMP_COL = \"send_timestamp\" # 2번 인덱스\n",
    "CSV_JOINT_COLS = [f\"joint_{i}\" for i in range(1, 7)] # 4~9번 인덱스\n",
    "CSV_POSE_COLS = [\"pose_x\", \"pose_y\", \"pose_z\", \"pose_a\", \"pose_b\", \"pose_r\"] # 10~15번 인덱스\n",
    "\n",
    "# --- 로깅 설정 ---\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "\n",
    "# --- 헬퍼 함수 (데이터 로딩 및 매칭) ---\n",
    "\n",
    "def load_sensor_data_from_csv(csv_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    주어진 CSV 파일에서 모든 행의 타임스탬프, 관절, 포즈 데이터를 읽어옵니다.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Loading sensor data from {csv_path}...\")\n",
    "    sensor_states = []\n",
    "    try:\n",
    "        with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            required_cols = [CSV_TIMESTAMP_COL] + CSV_JOINT_COLS + CSV_POSE_COLS\n",
    "            if not all(col in reader.fieldnames for col in required_cols):\n",
    "                logging.error(f\"CSV에 필요한 열이 부족합니다. 건너뜁니다. (파일: {csv_path})\")\n",
    "                return []\n",
    "\n",
    "            for i, row in enumerate(reader):\n",
    "                try:\n",
    "                    state = {\n",
    "                        'time': float(row[CSV_TIMESTAMP_COL]),\n",
    "                        'joints': np.array([float(row[col]) for col in CSV_JOINT_COLS], dtype=np.float32),\n",
    "                        'pose': np.array([float(row[col]) for col in CSV_POSE_COLS], dtype=np.float32)\n",
    "                    }\n",
    "                    sensor_states.append(state)\n",
    "                except (ValueError, TypeError) as e:\n",
    "                    logging.warning(f\"CSV {i+2}번째 행 파싱 실패 ({e}). 건너뜁니다.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"CSV 로드 중 오류: {e}\")\n",
    "        return []\n",
    "    logging.info(f\"✅ CSV 로드 성공! 총 {len(sensor_states)}개 데이터 포인트.\")\n",
    "    return sensor_states\n",
    "\n",
    "def extract_timestamp_from_filename(filename: str) -> Optional[float]:\n",
    "    try:\n",
    "        stem = os.path.splitext(filename)[0]\n",
    "        parts = stem.split('_')\n",
    "        timestamp_str = parts[-1] \n",
    "        return float(timestamp_str)\n",
    "    except (ValueError, IndexError):\n",
    "        logging.warning(f\"파일명 타임스탬프 파싱 불가: {filename}\")\n",
    "        return None\n",
    "\n",
    "def index_image_files(view_path: Path) -> List[Tuple[float, str]]:\n",
    "    \"\"\"\n",
    "    주어진 뷰 폴더 내의 모든 이미지 파일을 찾아 (하위 폴더 포함)\n",
    "    (타임스탬프, 경로) 리스트로 반환하고 시간순으로 정렬합니다.\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    if not view_path.is_dir():\n",
    "        logging.warning(f\"View 폴더를 찾을 수 없음: {view_path}\")\n",
    "        return []\n",
    "\n",
    "    for root, dirs, files in os.walk(view_path):\n",
    "        for file in files:\n",
    "            file_ext = os.path.splitext(file)[1].lower()\n",
    "            if file_ext in IMAGE_EXTENSIONS:\n",
    "                image_time = extract_timestamp_from_filename(file)\n",
    "                if image_time is not None:\n",
    "                    image_list.append((image_time, os.path.join(root, file)))\n",
    "    \n",
    "    image_list.sort() # 시간순 정렬\n",
    "    return image_list\n",
    "\n",
    "def find_closest_image_path(target_time: float, \n",
    "                            image_list: List[Tuple[float, str]], \n",
    "                            tolerance: float) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    정렬된 이미지 리스트(image_times 오름차순)에서 target_time과 가장 가까운 이미지를\n",
    "    이진 탐색(np.searchsorted)을 이용해 효율적으로 찾습니다.\n",
    "    \"\"\"\n",
    "    if not image_list:\n",
    "        return None\n",
    "\n",
    "    # (시간, 경로) 튜플에서 시간만 추출 (매번 생성 대신 캐싱 가능하지만, 여기서는 단순화)\n",
    "    image_times = np.array([t for t, p in image_list])\n",
    "    \n",
    "    idx = np.searchsorted(image_times, target_time, side='left')\n",
    "    \n",
    "    best_match_path = None\n",
    "    min_diff = float('inf')\n",
    "\n",
    "    # 찾은 위치(idx) 확인\n",
    "    if idx < len(image_times):\n",
    "        diff = abs(image_times[idx] - target_time)\n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            best_match_path = image_list[idx][1]\n",
    "    # 바로 전 위치(idx-1) 확인\n",
    "    if idx > 0:\n",
    "        diff = abs(image_times[idx-1] - target_time)\n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            best_match_path = image_list[idx-1][1]\n",
    "    \n",
    "    # 허용 오차(tolerance) 이내인 경우에만 경로 반환\n",
    "    if min_diff <= tolerance:\n",
    "        return best_match_path\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "# --- PyTorch IterableDataset 클래스 정의 ---\n",
    "\n",
    "class RealTimeMultiviewDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    'recv_all_...' 폴더에서 CSV와 이미지 파일을 실시간으로 읽고 매칭하는 IterableDataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 base_path: Path, \n",
    "                 view_config: Dict[str, str], \n",
    "                 image_transform: transforms.Compose, \n",
    "                 tolerance: float = 0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            base_path (Path): 'recv_all_...' 폴더들이 있는 기본 경로.\n",
    "            view_config (Dict[str, str]): {'View1_left': 'View1/left', ...} 형식의 뷰 설정.\n",
    "            image_transform (transforms.Compose): PIL 이미지에 적용할 변환.\n",
    "            tolerance (float): 센서-이미지 간 최대 허용 시간 차이 (초).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.base_path = base_path\n",
    "        self.view_config = view_config\n",
    "        self.view_keys_order = list(view_config.keys()) # 9개 뷰의 순서 고정\n",
    "        self.transform = image_transform\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "        if not self.base_path.is_dir():\n",
    "            raise FileNotFoundError(f\"기본 경로를 찾을 수 없습니다: {base_path}\")\n",
    "\n",
    "    def _process_sample(self, state: Dict[str, Any], image_paths: Dict[str, str]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"하나의 매칭된 샘플을 로드하고 텐서로 변환합니다.\"\"\"\n",
    "        \n",
    "        # 1. 이미지 로드 및 변환 (고정된 순서로)\n",
    "        image_tensors = []\n",
    "        for view_key in self.view_keys_order: # 9개 뷰 순서 고정\n",
    "            image_path = image_paths[view_key]\n",
    "            pil_image = Image.open(image_path).convert('RGB')\n",
    "            image_tensor = self.transform(pil_image)\n",
    "            image_tensors.append(image_tensor)\n",
    "\n",
    "        # (9, C, H, W) 형태로 스택\n",
    "        images_stacked = torch.stack(image_tensors, dim=0)\n",
    "\n",
    "        # 2. 센서 데이터 텐서 변환\n",
    "        joints = torch.tensor(state['joints'], dtype=torch.float32) # (6,)\n",
    "        pose = torch.tensor(state['pose'], dtype=torch.float32)     # (6,)\n",
    "\n",
    "        # 3. 모델 입력 딕셔너리로 반환\n",
    "        return {\n",
    "            'pixel_values': images_stacked, # (9, C, H, W)\n",
    "            'joints': joints,               # (6,)\n",
    "            'pose': pose,                   # (6,)\n",
    "            'timestamp': torch.tensor(state['time'], dtype=torch.float64) # (스칼라)\n",
    "        }\n",
    "\n",
    "    def __iter__(self) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        데이터셋 이터레이터. 세션 폴더를 순회하며 매칭된 데이터를 yield합니다.\n",
    "        \"\"\"\n",
    "        logging.info(f\"Dataset iterator 시작. {self.base_path} 탐색...\")\n",
    "\n",
    "        # 1. 'recv_all_...' 폴더 순회\n",
    "        session_paths = sorted([entry.path for entry in os.scandir(self.base_path) \n",
    "                                if entry.is_dir() and entry.name.startswith(\"recv_all_\")])\n",
    "        \n",
    "        if not session_paths:\n",
    "            logging.warning(f\"{self.base_path}에서 'recv_all_...' 폴더를 찾지 못했습니다.\")\n",
    "            return\n",
    "\n",
    "        for session_path_str in session_paths:\n",
    "            session_path = Path(session_path_str)\n",
    "            logging.info(f\"--- 세션 폴더 처리 시작: {session_path.name} ---\")\n",
    "\n",
    "            # 2. CSV 파일 로드 (세션당 1회)\n",
    "            csv_files = list(session_path.glob('robot_state_*.csv'))\n",
    "            if not csv_files:\n",
    "                logging.warning(f\"CSV 파일 없음. 건너뜁니다: {session_path.name}\")\n",
    "                continue\n",
    "            \n",
    "            sensor_states = load_sensor_data_from_csv(str(csv_files[0]))\n",
    "            if not sensor_states:\n",
    "                logging.warning(f\"센서 데이터 없음. 건너뜁니다: {session_path.name}\")\n",
    "                continue\n",
    "            \n",
    "            # 3. 모든 뷰의 이미지 파일 인덱싱 (세션당 1회)\n",
    "            image_indexes: Dict[str, List[Tuple[float, str]]] = {}\n",
    "            for view_key, view_subpath in self.view_config.items():\n",
    "                view_path = session_path / view_subpath\n",
    "                # logging.info(f\"  '{view_key}' 폴더 인덱싱...\")\n",
    "                image_indexes[view_key] = index_image_files(view_path)\n",
    "                if not image_indexes[view_key]:\n",
    "                     logging.warning(f\"  '{view_key}' 폴더에 이미지가 없습니다.\")\n",
    "            \n",
    "            logging.info(f\"  이미지 인덱싱 완료. {len(sensor_states)}개 센서 데이터와 매칭 시작...\")\n",
    "\n",
    "            # 4. 센서 타임스탬프 기준으로 매칭 및 yield\n",
    "            matched_count_in_session = 0\n",
    "            for state in sensor_states:\n",
    "                sensor_time = state['time']\n",
    "                matched_image_paths = {}\n",
    "                all_views_matched = True\n",
    "\n",
    "                # 모든 뷰(9개)에 대해 가장 가까운 이미지 찾기\n",
    "                for view_key in self.view_keys_order:\n",
    "                    closest_path = find_closest_image_path(\n",
    "                        sensor_time, \n",
    "                        image_indexes[view_key], \n",
    "                        self.tolerance\n",
    "                    )\n",
    "                    if closest_path:\n",
    "                        matched_image_paths[view_key] = closest_path\n",
    "                    else:\n",
    "                        all_views_matched = False\n",
    "                        break # 하나라도 실패하면 중단\n",
    "                \n",
    "                # 5. 모든 뷰가 매칭되었으면 데이터 처리 및 yield\n",
    "                if all_views_matched:\n",
    "                    try:\n",
    "                        processed_sample = self._process_sample(state, matched_image_paths)\n",
    "                        yield processed_sample\n",
    "                        matched_count_in_session += 1\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"샘플 처리 중 오류 (인덱스 {state['time']}): {e}\")\n",
    "            \n",
    "            logging.info(f\"--- 세션 처리 완료: {matched_count_in_session}개 데이터 포인트 생성 ---\")\n",
    "\n",
    "\n",
    "# --- 메인 실행 예시 (테스트용) ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # DINO / ImageNet 표준 이미지 변환\n",
    "    MEAN = [0.485, 0.456, 0.406]\n",
    "    STD  = [0.229, 0.224, 0.225]\n",
    "    RESIZE = 224\n",
    "    \n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Resize((RESIZE, RESIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=MEAN, std=STD),\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        # 1. 데이터셋 인스턴스 생성\n",
    "        print(\"RealTimeMultiviewDataset 생성 중...\")\n",
    "        dataset = RealTimeMultiviewDataset(\n",
    "            base_path=BASE_PATH,\n",
    "            view_config=VIEW_CONFIG,\n",
    "            image_transform=image_transform,\n",
    "            tolerance=MATCH_TOLERANCE_SEC\n",
    "        )\n",
    "        print(\"데이터셋 생성 완료.\")\n",
    "        \n",
    "        # 2. DataLoader 생성\n",
    "        print(\"DataLoader 생성 중... (Batch Size = 4)\")\n",
    "        # IterableDataset은 shuffle=True를 DataLoader에서 직접 못하므로,\n",
    "        # RLDS 로더처럼 내부 버퍼링이 필요하지만, 여기서는 순차 로딩으로 테스트합니다.\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=4,\n",
    "            num_workers=0, # IterableDataset은 멀티워커 설정 시 주의 필요 (0이 가장 안전)\n",
    "            # collate_fn은 기본값(default_collate) 사용\n",
    "        )\n",
    "        print(\"DataLoader 생성 완료.\")\n",
    "\n",
    "        # 3. 첫 번째 배치 가져오기\n",
    "        print(\"\\n첫 번째 배치 로딩 시도...\")\n",
    "        start_time = time.time()\n",
    "        first_batch = next(iter(dataloader))\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"✅ 첫 번째 배치 로드 성공! (소요 시간: {end_time - start_time:.2f}초)\")\n",
    "        print(\"\\n\" + \"=\"*30)\n",
    "        print(\" 첫 번째 배치 정보 (Batch 0)\")\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        for key, value in first_batch.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                print(f\"  Key: '{key}'\")\n",
    "                print(f\"    Shape: {value.shape}\") # (B, 9, C, H, W) 또는 (B, 6)\n",
    "                print(f\"    Dtype: {value.dtype}\")\n",
    "            else:\n",
    "                print(f\"  Key: '{key}', Type: {type(value)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n테스트 실행 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3251ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
